{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agu3ro/Pytorch-DL/blob/main/07_07_SuperGradients_Image_Classification_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!wget https://dissect.csail.mit.edu/datasets/miniplaces.zip --no-check-certificate && unzip miniplaces.zip"
      ],
      "metadata": {
        "id": "mlORlYbfllkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üëãüèΩ What's up! It's [Harpreet](https://twitter.com/DataScienceHarp)\n",
        "\n",
        "I'll be guiding you through this notebook. At any point, if you get stuck or have questions, there are three ways to get in touch:\n",
        "\n",
        "1) Send me an email with your issue: harpreet.sahota@deci.ai\n",
        "\n",
        "2) Hop into the [Deep Learning Daily (powered by Deci) Discord server](https://discord.gg/p9ecgRhDR8), and let me know what your question is.\n",
        "\n",
        "3) [Open an issue on GitHub](https://github.com/Deci-AI/super-gradients/issues/new/choose)\n",
        "\n",
        "---\n",
        "\n",
        "# üñºÔ∏è Image Classification Project Template with SuperGradients\n",
        "\n",
        "This notebook template is for data that is already in ImageFolder format.\n",
        "\n",
        "If you are unfamiliar with ImageFolder format, it looks like this:\n",
        "\n",
        "```\n",
        "‚îú‚îÄ‚îÄ train\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ class1\n",
        "|      ‚îú‚îÄ‚îÄ 1.jpg\n",
        "‚îÇ      ‚îú‚îÄ‚îÄ 2.jpg\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ class2\n",
        "|      ‚îú‚îÄ‚îÄ 1.jpg\n",
        "‚îÇ      ‚îú‚îÄ‚îÄ 2.jpg\n",
        "‚îú‚îÄ‚îÄ valid\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ class1\n",
        "|      ‚îú‚îÄ‚îÄ 1.jpg\n",
        "‚îÇ      ‚îú‚îÄ‚îÄ 2.jpg\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ class2\n",
        "|      ‚îú‚îÄ‚îÄ 1.jpg\n",
        "‚îÇ      ‚îú‚îÄ‚îÄ 2.jpg\n",
        "```\n",
        "\n",
        "With parent folder repeating for validtaion and testing data."
      ],
      "metadata": {
        "id": "M_LdvkGuIx9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install super_gradients==3.2.0"
      ],
      "metadata": {
        "id": "4Siqg0CJDbCI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import super_gradients\n",
        "from super_gradients.common.object_names import Models\n",
        "from super_gradients.training import Trainer, training_hyperparams, models"
      ],
      "metadata": {
        "id": "wU8-ACNWa_Eh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "outputId": "f796445f-f61b-4c70-df66-8eb0cf8fa0cb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "_ARRAY_API not found",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "numpy.core.multiarray failed to import",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-29f71b8cd568>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msuper_gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msuper_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_names\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msuper_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_hyperparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/super_gradients/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msuper_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minit_trainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_distributed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msuper_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets_utils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataAugmentation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKDTrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQATTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msuper_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mARCHITECTURES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msuper_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msanity_check\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0menv_sanity_check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msuper_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed_training_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msetup_device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/super_gradients/training/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# PACKAGE IMPORTS FOR EXTERNAL USAGE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msuper_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed_training_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdistributed_training_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msuper_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets_utils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataAugmentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msuper_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msg_trainer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msuper_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkd_trainer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKDTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/super_gradients/training/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmake_divisible\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m )\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msuper_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madapt_state_dict_to_fit_model_layer_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_informative_runtime_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msuper_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_version_is_greater_or_equal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msuper_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mraise_if_unused_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn_if_unused_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/super_gradients/training/utils/checkpoint_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msuper_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_types\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStrictLoad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msuper_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplicit_params_validator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexplicit_params_validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msuper_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_interfaces\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHasPredict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msuper_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrained_models\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMODEL_URLS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msuper_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed_training_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_local_rank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_for_the_master\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/super_gradients/module_interfaces/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodule_interfaces\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHasPredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHasPreprocessingParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSupportsReplaceNumClasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexportable_detector\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExportableObjectDetectionModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAbstractObjectDetectionDecodingModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"HasPredict\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"HasPreprocessingParams\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SupportsReplaceNumClasses\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ExportableObjectDetectionModel\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"AbstractObjectDetectionDecodingModule\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/super_gradients/module_interfaces/module_interfaces.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping_extensions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProtocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruntime_checkable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msuper_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProcessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/super_gradients/training/processing/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from .processing import (\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mStandardizeImage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mDetectionRescale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mDetectionLongestMaxSizeRescale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mDetectionBottomRightPadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/super_gradients/training/processing/processing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msuper_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_names\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProcessings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msuper_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregister_processing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msuper_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets_conf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCOCO_DETECTION_CLASSES_LIST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMAGENET_CLASSES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m from super_gradients.training.transforms.utils import (\n\u001b[1;32m     13\u001b[0m     \u001b[0m_rescale_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/super_gradients/training/datasets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msuper_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_augmentation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataAugmentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msuper_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msg_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mListDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDirectoryDataSet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msuper_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_datasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageNetDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCifar10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCifar100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m from super_gradients.training.datasets.detection_datasets import (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/super_gradients/training/datasets/sg_dataset.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfolder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefault_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msuper_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIMG_EXTENSIONS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/super_gradients/training/utils/media/image.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;31m# cbook must import matplotlib only within function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;31m# definitions, so it is safe to import from it here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_docstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcsetup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msanitize_sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMatplotlibDeprecationWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/rcsetup.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mls_mapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mColormap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_color_like\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fontconfig_pattern\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparse_fontconfig_pattern\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enums\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mJoinStyle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCapStyle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_cm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_color_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBASE_COLORS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTABLEAU_COLORS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCSS4_COLORS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXKCD_COLORS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/scale.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m from matplotlib.ticker import (\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mNullFormatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mScalarFormatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLogFormatterSciNotation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLogitFormatter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mNullLocator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLogLocator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoLocator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoMinorLocator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/ticker.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0m_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/transforms.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m from matplotlib._path import (\n\u001b[0m\u001b[1;32m     50\u001b[0m     affine_transform, count_bboxes_overlapping_bbox, update_path_extents)\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚öíÔ∏è Config\n",
        "\n",
        "This holds variables for the notebook.\n",
        "\n",
        "You will define the model, training params, image type, number of classes, and\n",
        "relevant directories in this class.\n",
        "\n",
        "\n",
        "\n",
        "If you have a question you can leave a comment on this notebook, or visit the community and post it in the [Q&A section](https://www.deeplearningdaily.community).\n"
      ],
      "metadata": {
        "id": "gPKlFKEJDfWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class config:\n",
        "    # specify the paths to datasets\n",
        "    ROOT_DIR = Path()\n",
        "    TRAIN_DIR = ROOT_DIR.joinpath('miniplaces/train')\n",
        "    TEST_DIR = ROOT_DIR.joinpath('miniplaces/test')\n",
        "    VAL_DIR = ROOT_DIR.joinpath('miniplaces/val')\n",
        "\n",
        "    CHECKPOINT_DIR = 'checkpoints'\n",
        "    EXPERIMENT_NAME = \"YOUR-EXPERIMENT-NAME\"\n",
        "    PRETRAINED_WEIGHTS = 'imagenet'\n",
        "\n",
        "    # note if you're averaging the best model then replace \"ckpt_best.pth\" with \"average_model.pth\"\n",
        "    CHECKPOINT_TYPE = \"ckpt_best.pth\"\n",
        "\n",
        "    # set the input height and width\n",
        "    INPUT_HEIGHT = 224\n",
        "    INPUT_WIDTH = 224\n",
        "\n",
        "    # what mean and std do you want to standardize to\n",
        "    NORM_MEAN = [0.485, 0.456, 0.406]\n",
        "    NORM_STD = [0.229, 0.224, 0.225]\n",
        "\n",
        "    BATCH_SIZE = 32\n",
        "    MODEL_NAME = \"CHOOSE-YOUR-MODEL\"\n",
        "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    TRAINING_PARAMS = 'training_hyperparams/default_train_params'\n",
        "    LOSS = \"cross_entropy\"\n",
        "    OPTIMIZER = 'Adam'\n",
        "    EPOCHS = 100\n",
        "    INITIAL_LR = 3e-4\n",
        "\n",
        "    NUM_CLASSES = 100\n",
        "\n",
        "    METRICS_LIST = ['Accuracy', 'Top5']"
      ],
      "metadata": {
        "id": "5bsqNIJ7DoO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üíæ Dataset and Dataloader\n",
        "\n",
        "You can experiment with any transforms you'd like. [Here](https://pytorch.org/vision/stable/auto_examples/plot_transforms.html#sphx-glr-auto-examples-plot-transforms-py) are the torchvision transforms you can use."
      ],
      "metadata": {
        "id": "Ic8WXQILKc1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the transform\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((config.INPUT_HEIGHT, config.INPUT_WIDTH)),\n",
        "    transforms.ToTensor(),  # convert image to PyTorch tensor\n",
        "    transforms.Normalize(mean=config.NORM_MEAN, std=config.NORM_STD)\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((config.INPUT_HEIGHT, config.INPUT_WIDTH)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=config.NORM_MEAN, std=config.NORM_STD)\n",
        "])\n",
        "\n",
        "# define the datasets\n",
        "train_dataset = datasets.ImageFolder(config.TRAIN_DIR,\n",
        "                                     transform=train_transform\n",
        "                                     )\n",
        "\n",
        "val_dataset = datasets.ImageFolder(config.VAL_DIR,\n",
        "                                   transform=test_transform\n",
        "                                   )\n",
        "\n",
        "test_dataset = datasets.ImageFolder(config.TEST_DIR,\n",
        "                                    transform=test_transform\n",
        "                                    )\n",
        "\n",
        "# define the dataloaders\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                           batch_size=config.BATCH_SIZE,\n",
        "                                           shuffle=True\n",
        "                                           )\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset,\n",
        "                                         batch_size=config.BATCH_SIZE,\n",
        "                                         shuffle=False\n",
        "                                         )\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
        "                                          batch_size=config.BATCH_SIZE,\n",
        "                                          shuffle=False\n",
        "                                          )"
      ],
      "metadata": {
        "id": "PzQIE96DKdKf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "8d60aa55-1a97-488a-9dab-337c4ff01092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'miniplaces/test'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-e5ee4e974cba>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m                                    )\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m test_dataset = datasets.ImageFolder(config.TEST_DIR,\n\u001b[0m\u001b[1;32m     24\u001b[0m                                     \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mallow_empty\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     ):\n\u001b[0;32m--> 328\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    147\u001b[0m     ) -> None:\n\u001b[1;32m    148\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         samples = self.make_dataset(\n\u001b[1;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \"\"\"\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDatasetFolder\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \"\"\"\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'miniplaces/test'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üéõÔ∏è Training Params\n",
        "\n",
        "You'll use the [default training parameters](https://github.com/Deci-AI/super-gradients/blob/master/src/super_gradients/recipes/training_hyperparams/default_train_params.yaml) for this notebook."
      ],
      "metadata": {
        "id": "GG6RomNeGCnc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_params =  training_hyperparams.get(config.TRAINING_PARAMS)"
      ],
      "metadata": {
        "id": "Yn5OpeiPGEsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEHNISs7devZ",
        "outputId": "55915bb2-3018-4874-ef78-cd48ef2b9d01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'resume': False,\n",
              " 'resume_path': None,\n",
              " 'resume_from_remote_sg_logger': False,\n",
              " 'ckpt_name': 'ckpt_latest.pth',\n",
              " 'lr_mode': None,\n",
              " 'lr_schedule_function': None,\n",
              " 'lr_warmup_epochs': 0,\n",
              " 'lr_warmup_steps': 0,\n",
              " 'lr_cooldown_epochs': 0,\n",
              " 'warmup_initial_lr': None,\n",
              " 'step_lr_update_freq': None,\n",
              " 'cosine_final_lr_ratio': 0.01,\n",
              " 'warmup_mode': 'linear_epoch_step',\n",
              " 'lr_updates': [],\n",
              " 'pre_prediction_callback': None,\n",
              " 'optimizer': 'SGD',\n",
              " 'optimizer_params': {},\n",
              " 'load_opt_params': True,\n",
              " 'zero_weight_decay_on_bias_and_bn': False,\n",
              " 'loss': None,\n",
              " 'criterion_params': {},\n",
              " 'ema': False,\n",
              " 'ema_params': {'decay': 0.9999, 'decay_type': 'exp', 'beta': 15},\n",
              " 'train_metrics_list': [],\n",
              " 'valid_metrics_list': [],\n",
              " 'metric_to_watch': 'Accuracy',\n",
              " 'greater_metric_to_watch_is_better': True,\n",
              " 'launch_tensorboard': False,\n",
              " 'tensorboard_port': None,\n",
              " 'tb_files_user_prompt': False,\n",
              " 'save_tensorboard_to_s3': False,\n",
              " 'precise_bn': False,\n",
              " 'precise_bn_batch_size': None,\n",
              " 'sync_bn': False,\n",
              " 'silent_mode': False,\n",
              " 'mixed_precision': False,\n",
              " 'save_ckpt_epoch_list': [],\n",
              " 'average_best_models': True,\n",
              " 'dataset_statistics': False,\n",
              " 'batch_accumulate': 1,\n",
              " 'run_validation_freq': 1,\n",
              " 'run_test_freq': 1,\n",
              " 'save_model': True,\n",
              " 'seed': 42,\n",
              " 'phase_callbacks': [],\n",
              " 'log_installed_packages': True,\n",
              " 'clip_grad_norm': None,\n",
              " 'ckpt_best_name': 'ckpt_best.pth',\n",
              " 'max_train_batches': None,\n",
              " 'max_valid_batches': None,\n",
              " 'sg_logger': 'base_sg_logger',\n",
              " 'sg_logger_params': {'tb_files_user_prompt': False, 'launch_tensorboard': False, 'tensorboard_port': None, 'save_checkpoints_remote': False, 'save_tensorboard_remote': False, 'save_logs_remote': False, 'monitor_system': True},\n",
              " 'torch_compile': False,\n",
              " 'torch_compile_loss': False,\n",
              " 'torch_compile_options': {'mode': 'reduce-overhead', 'fullgraph': False, 'dynamic': False, 'backend': 'inductor', 'options': None, 'disable': False},\n",
              " '_convert_': 'all'}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_params['loss'] = config.LOSS\n",
        "training_params['optimizer'] = config.OPTIMIZER\n",
        "training_params['max_epochs'] = config.EPOCHS\n",
        "training_params['train_metrics_list'] = config.METRICS_LIST\n",
        "training_params['valid_metrics_list'] = config.METRICS_LIST\n",
        "training_params['initial_lr'] = config.INITIAL_LR"
      ],
      "metadata": {
        "id": "IX_FYlaQdVAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bkhFGTQc3Cs",
        "outputId": "4df14d13-6455-4c4a-e43b-217413044d6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'resume': False,\n",
              " 'resume_path': None,\n",
              " 'resume_from_remote_sg_logger': False,\n",
              " 'ckpt_name': 'ckpt_latest.pth',\n",
              " 'lr_mode': None,\n",
              " 'lr_schedule_function': None,\n",
              " 'lr_warmup_epochs': 0,\n",
              " 'lr_warmup_steps': 0,\n",
              " 'lr_cooldown_epochs': 0,\n",
              " 'warmup_initial_lr': None,\n",
              " 'step_lr_update_freq': None,\n",
              " 'cosine_final_lr_ratio': 0.01,\n",
              " 'warmup_mode': 'linear_epoch_step',\n",
              " 'lr_updates': [],\n",
              " 'pre_prediction_callback': None,\n",
              " 'optimizer': 'SGD',\n",
              " 'optimizer_params': {},\n",
              " 'load_opt_params': True,\n",
              " 'zero_weight_decay_on_bias_and_bn': False,\n",
              " 'loss': 'cross_entropy',\n",
              " 'criterion_params': {},\n",
              " 'ema': False,\n",
              " 'ema_params': {'decay': 0.9999, 'decay_type': 'exp', 'beta': 15},\n",
              " 'train_metrics_list': ['Accuracy', 'Top5'],\n",
              " 'valid_metrics_list': ['Accuracy', 'Top5'],\n",
              " 'metric_to_watch': 'Accuracy',\n",
              " 'greater_metric_to_watch_is_better': True,\n",
              " 'launch_tensorboard': False,\n",
              " 'tensorboard_port': None,\n",
              " 'tb_files_user_prompt': False,\n",
              " 'save_tensorboard_to_s3': False,\n",
              " 'precise_bn': False,\n",
              " 'precise_bn_batch_size': None,\n",
              " 'sync_bn': False,\n",
              " 'silent_mode': False,\n",
              " 'mixed_precision': False,\n",
              " 'save_ckpt_epoch_list': [],\n",
              " 'average_best_models': True,\n",
              " 'dataset_statistics': False,\n",
              " 'batch_accumulate': 1,\n",
              " 'run_validation_freq': 1,\n",
              " 'run_test_freq': 1,\n",
              " 'save_model': True,\n",
              " 'seed': 42,\n",
              " 'phase_callbacks': [],\n",
              " 'log_installed_packages': True,\n",
              " 'clip_grad_norm': None,\n",
              " 'ckpt_best_name': 'ckpt_best.pth',\n",
              " 'max_train_batches': None,\n",
              " 'max_valid_batches': None,\n",
              " 'sg_logger': 'base_sg_logger',\n",
              " 'sg_logger_params': {'tb_files_user_prompt': False, 'launch_tensorboard': False, 'tensorboard_port': None, 'save_checkpoints_remote': False, 'save_tensorboard_remote': False, 'save_logs_remote': False, 'monitor_system': True},\n",
              " 'torch_compile': False,\n",
              " 'torch_compile_loss': False,\n",
              " 'torch_compile_options': {'mode': 'reduce-overhead', 'fullgraph': False, 'dynamic': False, 'backend': 'inductor', 'options': None, 'disable': False},\n",
              " '_convert_': 'all',\n",
              " 'max_epochs': 100,\n",
              " 'initial_lr': 0.0003}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are a few things you can try to see how you fare: try a different optimizer (you can the optimizer by using a passing of the following strings \"Adam\", \"AdamW\", \"SGD\", or \"RMSProp\"."
      ],
      "metadata": {
        "id": "6VFsBMDMcOQX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üë©üèΩ‚Äçü¶≥ Instantiate model\n",
        "\n"
      ],
      "metadata": {
        "id": "Glmd2R98GZmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.get(config.MODEL_NAME,\n",
        "                   num_classes = config.NUM_CLASSES,\n",
        "                   pretrained_weights=config.PRETRAINED_WEIGHTS)"
      ],
      "metadata": {
        "id": "rht8gYzaGFFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üèãüèæ Instantiate trainer"
      ],
      "metadata": {
        "id": "ZliLB58FGFYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(ckpt_root_dir=config.CHECKPOINT_DIR,\n",
        "                  experiment_name=config.EXPERIMENT_NAME\n",
        "                  )"
      ],
      "metadata": {
        "id": "uBGak3EPGHVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ü¶æ Train model"
      ],
      "metadata": {
        "id": "7zwKpRYiGcIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train(model=model,\n",
        "              training_params=training_params,\n",
        "              train_loader=train_dataloader,\n",
        "              valid_loader=valid_dataloader)"
      ],
      "metadata": {
        "id": "VaavBbnFGcat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üôåüèº Load best model"
      ],
      "metadata": {
        "id": "OtDlvFYp4OAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = models.get(config.MODEL_NAME,\n",
        "                        num_classes=config.NUM_CLASSES,\n",
        "                        checkpoint_path=os.path.join(full_model_trainer.checkpoints_dir_path,\n",
        "                                                     config.CHECKPOINT_TYPE)\n",
        "                        )"
      ],
      "metadata": {
        "id": "sguIHkpa4Og3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üßê Evaluate on test set"
      ],
      "metadata": {
        "id": "u-n1DyypGkjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.test(model=best_model,\n",
        "             test_loader=test_dataloader,\n",
        "             test_metrics_list=config.METRICS_LIST\n",
        "             )"
      ],
      "metadata": {
        "id": "Z8H6camVGmY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîÆ Predicting with the best model"
      ],
      "metadata": {
        "id": "mKzUsIQlgRPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from super_gradients.training.processing.processing import default_imagenet_processing_params\n",
        "processing_params = default_imagenet_processing_params()\n",
        "processing_params['class_names'] = train_dataset.classes\n",
        "best_model.set_dataset_processing_params(**processing_params)"
      ],
      "metadata": {
        "id": "Q6fgi85eeuvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_url = 'ENTER-SOME-URL-HERE'\n",
        "best_model.predict(img_url).show()"
      ],
      "metadata": {
        "id": "uRJl5IJBeu4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your homework\n",
        "\n",
        "Copy/fork this notebook and try some different architectures.\n",
        "\n",
        "If you have a question you can leave a comment on this notebook, or visit the community and post it in the [Q&A section](https://www.deeplearningdaily.community).\n",
        "\n",
        "## Use a different pretrained model\n",
        "\n",
        "You can change the model you use. Take a look at the [SG model zoo](https://github.com/Deci-AI/super-gradients/blob/master/documentation/source/model_zoo.md)\n",
        "\n",
        "For example, if you wanted to use RegNet you would do the following:\n",
        "\n",
        "```\n",
        "resnet_imagenet_model = models.get(model_name='regnetY800', num_classes=NUM_CLASSES, pretrained_weights='imagenet)\n",
        "resnet_params =  training_hyperparams.get('training_hyperparams/imagenet_regnetY_train_params')\n",
        "```\n",
        "\n",
        "Note you can also pass 'model_name=regnetY200', 'model_name=regnetY400', 'model_name=regnetY600' to try a variety of the architecture\n",
        "\n",
        "For ResNet50, you would do:\n",
        "\n",
        "```\n",
        "resnet_imagenet_model = models.get(model_name='resnet50', num_classes=NUM_CLASSES, pretrained_weights='imagenet)\n",
        "resnet_params =  training_hyperparams.get('training_hyperparams/imagenet_resnet50_train_params')\n",
        "```\n",
        "\n",
        "Note you can also pass 'model_name=resnet18' or 'model_name=resnet34' to try a variety of the architecture\n",
        "\n",
        "For MobileNetV2, you would do:\n",
        "\n",
        "```\n",
        "mobilenet_imagenet_model = models.get(model_name='mobilenet_v2', num_classes=NUM_CLASSES, pretrained_weights='imagenet)\n",
        "resnet_params =  training_hyperparams.get('training_hyperparams/imagenet_mobilenetv2_train_params')\n",
        "```\n",
        "\n",
        "For MobileNetV3, you would do:\n",
        "\n",
        "```\n",
        "mobilenet_imagenet_model = models.get(model_name='mobilenet_v3_large', num_classes=NUM_CLASSES, pretrained_weights='imagenet)\n",
        "resnet_params =  training_hyperparams.get('training_hyperparams/imagenet_mobilenetv3_train_params')\n",
        "```\n",
        "\n",
        "Note you can also pass 'model_name=mobilenet_v3_small' to try a variety of the architecture\n",
        "\n",
        "\n",
        "For ViT, you would do:\n",
        "\n",
        "\n",
        "```\n",
        "vit_imagenet_model = models.get(model_name='vit_base', num_classes=NUM_CLASSES, pretrained_weights='imagenet')\n",
        "vit_params =  training_hyperparams.get(\"training_hyperparams/imagenet_vit_train_params\")\n",
        "```\n",
        "\n",
        "Note you can also pass 'model_name=vit_large' to try a variety of the architecture\n",
        "\n",
        "\n",
        "I encourage you play around with different optimizers, all you have to do is change the value of `training_params[\"optimizer\"]`. You can use one of ['Adam','SGD','RMSProp'] out of the box. You can play around with the optimizer params as well.\n",
        "\n",
        "In general, play and tweak around the training recipies...\n",
        "\n",
        "## Training recipes\n",
        "\n",
        "SuperGradients has a number of [training recipes](https://github.com/Deci-AI/super-gradients/tree/master/src/super_gradients/recipes) you can use. [See here](https://github.com/Deci-AI/super-gradients/blob/master/src/super_gradients/recipes/training_hyperparams/default_train_params.yaml) for more information about the training params."
      ],
      "metadata": {
        "id": "grHxgV51Jv_G"
      }
    }
  ]
}